/home/sam/github/data-fastapi
├── alembic
│   ├── env.py
│   ├── README
│   ├── script.py.mako
│   └── versions
├── alembic.ini
├── app
│   ├── api
│   │   ├── v1
│   │   │   └── dataset_routes.py
│   │   └── v2
│   ├── config
│   │   ├── __init__.py
│   │   └── settings.py
│   ├── core
│   │   ├── database
│   │   │   ├── __init__.py
│   │   │   ├── odm_connection.py
│   │   │   └── orm_connection.py
│   │   └── security.py
│   ├── __init__.py
│   ├── main.py
│   ├── models
│   │   ├── nosql_models
│   │   │   ├── docs_categ.py
│   │   │   └── __init__.py
│   │   └── sql_models
│   │       ├── docs_categ_metadata.py
│   │       └── __init__.py
│   ├── routes
│   │   ├── dataset_routes.py
│   │   └── __init__.py
│   └── services
│       └── basic_crud_operations.py
├── code_report.py
├── custom_tree_and_files_corrected.txt
├── .env
├── .env.sample
├── .gitignore
├── LICENSE
├── logs
├── README.md
├── scripts
├── terraform
└── tests

19 directories, 27 files


=== Content of /home/sam/github/data-fastapi/code_report.py ===

Code present but not reported for space reasons

=== Content of /home/sam/github/data-fastapi/README.md ===

# Data-FastAPI

## Overview

`data-fastapi` is a comprehensive API designed for selling datasets. It supports various data types, both structured and unstructured, and offers modular, scalable access to data via an API key authentication system.

## Features

- Support for multiple databases: MongoDB, PostgreSQL, Redis, and a Data Lakehouse.
- Local and cloud deployment options for cost-effective development and scalability.
- API key authentication for secure and controlled data access.
- Modular structure for easy maintenance and scalability.

## Getting Started

data-fastapi/
│
├── app/ # Application source files
│ ├── api/ # API routes and endpoints
│ ├── models/ # Database models (SQLAlchemy and Beanie)
│ ├── services/ # Business logic
│ ├── dependencies/ # Dependencies for FastAPI (e.g., database session, security)
│ └── main.py # Entry point of the FastAPI application
│
├── tests/ # Unit and integration tests
│
├── scripts/ # Utility scripts (e.g., setup, deployment)
│
├── docker/ # Dockerfiles and docker-compose files
│
├── terraform/ # Terraform files for infrastructure setup
│
├── .env.sample # Sample environment variables file
│
├── requirements.txt # Python dependencies
│
└── README.md # Project documentation

### Prerequisites

- Docker
- Python 3.8+
- Terraform (for cloud deployment)

### Installation

Clone the repository:

```
git clone https://github.com/yourusername/data-fastapi.git
```

Install dependencies:

```
pip install -r requirements.txt
```

### Setting Up Local Environment

Copy `.env.sample` to create a `.env` file and adjust the variables to suit your local environment.

Run the Docker containers for databases:

```
docker-compose up -d
```

### Running the Application

Start the FastAPI application:

```
uvicorn app.main:app --reload
```

## API Documentation

Access the API documentation at `http://localhost:8000/docs`.

## Testing

Run tests using:

```
pytest
```

## Deployment

Refer to the `terraform/` directory for cloud deployment and `docker/` for containerization details.

## Contributing

Contributions, issues, and feature requests are welcome!

## License

Distributed under the MIT License. See `LICENSE` for more information.

## Contact

Your Name - your@email.com
Project Link: https://github.com/yourusername/data-fastapi


=== Content of /home/sam/github/data-fastapi/alembic.ini ===

# A generic, single database configuration.

[alembic]
# path to migration scripts
script_location = alembic

# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s
# Uncomment the line below if you want the files to be prepended with date and time
# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file
# for all available tokens
# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.
prepend_sys_path = .

# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python>=3.9 or backports.zoneinfo library.
# Any required deps can installed by adding `alembic[tz]` to the pip requirements
# string value is passed to ZoneInfo()
# leave blank for localtime
# timezone =

# max length of characters to apply to the
# "slug" field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to alembic/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by "version_path_separator" below.
# version_locations = %(here)s/bar:%(here)s/bat:alembic/versions

# version path separator; As mentioned above, this is the character used to split
# version_locations. The default within new alembic.ini files is "os", which uses os.pathsep.
# If this key is omitted entirely, it falls back to the legacy behavior of splitting on spaces and/or commas.
# Valid values for version_path_separator are:
#
# version_path_separator = :
# version_path_separator = ;
# version_path_separator = space
version_path_separator = os  # Use os.pathsep. Default configuration used for new projects.

# set to 'true' to search source files recursively
# in each "version_locations" directory
# new in Alembic version 1.10
# recursive_version_locations = false

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

sqlalchemy.url = driver://user:pass@localhost/dbname


[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console_scripts runner, against the "black" entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# lint with attempts to fix using "ruff" - use the exec runner, execute a binary
# hooks = ruff
# ruff.type = exec
# ruff.executable = %(here)s/.venv/bin/ruff
# ruff.options = --fix REVISION_SCRIPT_FILENAME

# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S


=== Content of /home/sam/github/data-fastapi/.env.sample ===

# .env file
ENVIRONMENT=development  # or 'production'

# Generic SQL Database
SQLALCHEMY_DATABASE_URL_DEV=sqlalchemy_database_url_for_dev
SQLALCHEMY_DATABASE_URL_PROD=sqlalchemy_database_url_for_prod

# MongoDB
MONGODB_URL_DEV=mongodb://localhost:27017/mydatabase
MONGODB_URL_PROD=mongodb://prod_host:27017/prod_db

# Add similar variables for Redis and other databases


=== Content of /home/sam/github/data-fastapi/app/main.py ===

from fastapi import FastAPI
from .api.v1 import dataset_routes

app = FastAPI()

app.include_router(dataset_routes.router, prefix="/v1")


=== Content of /home/sam/github/data-fastapi/app/config/settings.py ===

# app/config/settings.py
from pydantic import BaseSettings


class Settings(BaseSettings):
    environment: str = "development"
    sqlalchemy_database_url: str
    mongodb_url: str
    api_key: str  # Add the API key variable

    class Config:
        env_file = ".env"


settings = Settings()


=== Content of /home/sam/github/data-fastapi/app/core/security.py ===

# app/core/security.py
from fastapi import Security, HTTPException
from fastapi.security.api_key import APIKeyHeader
from app.config.settings import settings

api_key_header = APIKeyHeader(name="X-API-Key")


async def get_api_key(api_key_header: str = Security(api_key_header)):
    if api_key_header != settings.api_key:
        raise HTTPException(status_code=403, detail="Invalid API Key")
    return api_key_header


=== Content of /home/sam/github/data-fastapi/app/core/database/odm_connection.py ===

# # app/core/database/odm_connection.py
# from beanie import init_beanie
# from motor.motor_asyncio import AsyncIOMotorClient
# from app.config.settings import settings
# from app.models.nosql_models.docs_categ import DocsNameCateg


# async def init_odm():
#     client = AsyncIOMotorClient(settings.mongodb_url)
#     database = client.get_default_database()
#     await init_beanie(
#         database, document_models=[DocsNameCateg]
#     )  # List all Beanie documents


=== Content of /home/sam/github/data-fastapi/app/core/database/orm_connection.py ===

# app/core/database/orm_connection.py
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, declarative_base
from contextlib import contextmanager
from app.config.settings import settings

DATABASE_URL = settings.sqlalchemy_database_url

engine = create_engine(DATABASE_URL)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

Base = declarative_base()

# Use Alembic for database migrations instead of create_all
# Base.metadata.create_all(engine)


@contextmanager
def session_scope():
    """Provide a transactional scope around a series of operations."""
    session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception:
        session.rollback()
        raise
    finally:
        session.close()


=== Content of /home/sam/github/data-fastapi/app/routes/dataset_routes.py ===



=== Content of /home/sam/github/data-fastapi/app/models/sql_models/docs_categ_metadata.py ===

from sqlalchemy import Column, Integer, String, DateTime, Float, ForeignKey
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from datetime import datetime

Base = declarative_base()


class PdfDownload(Base):
    __tablename__ = "pdf_downloads"
    id = Column(Integer, primary_key=True)
    url = Column(String, unique=True)
    status = Column(String)  # 'success', 'failed', etc.
    notes = Column(String)  # Additional information like error messages
    download_path = Column(String)
    downloaded_at = Column(DateTime, default=datetime.utcnow)
    keywords_namefile = Column(String)  # Nuova colonna per le parole chiave

    def __repr__(self):
        return f"<PdfDownload(url='{self.url}', status='{self.status}', downloaded_at='{self.downloaded_at}', keywords_namefile='{self.keywords_namefile}')>"


=== Content of /home/sam/github/data-fastapi/app/models/nosql_models/docs_categ.py ===

from beanie import Document
from datetime import datetime
from typing import List, Dict


class DocsNameCateg(Document):
    id_file: str
    file_name: str
    url: str
    date_download: datetime
    date_extraction: datetime
    elements: List[Dict]

    class Settings:
        collection = "docs"


=== Content of /home/sam/github/data-fastapi/app/services/basic_crud_operations.py ===

# app/services/basic_crud_operations.py
from typing import Type, TypeVar, Generic, List
from sqlalchemy.orm import Session
from pydantic import BaseModel

T = TypeVar("T", bound=BaseModel)  # T is a TypeVar bound to BaseModel (from Pydantic)


class CRUDOperations(Generic[T]):
    def __init__(self, model: Type[T]):
        """
        CRUD object with generic methods to Create, Read, Update, Delete (CRUD).

        :param model: A SQLAlchemy model class
        """
        self.model = model

    def create(self, db: Session, *, obj_in: T) -> T:
        """
        Create a new database record.

        :param db: SQLAlchemy database session.
        :param obj_in: Pydantic model of the object to be created.
        :return: The created database record.
        """
        db_obj = self.model(**obj_in.dict())  # Create a new SQLAlchemy model instance
        db.add(db_obj)
        db.commit()
        db.refresh(db_obj)
        return db_obj

    def read(self, db: Session, id: int) -> T:
        """
        Get a single record by ID.

        :param db: SQLAlchemy database session.
        :param id: ID of the record to retrieve.
        :return: The database record object.
        """
        return db.query(self.model).filter(self.model.id == id).first()

    def update(self, db: Session, *, db_obj: T, obj_in: T) -> T:
        """
        Update a database record.

        :param db: SQLAlchemy database session.
        :param db_obj: SQLAlchemy model instance to update.
        :param obj_in: Pydantic model of the object with updated fields.
        :return: The updated database record.
        """
        obj_data = obj_in.dict(exclude_unset=True)
        for field in obj_data:
            setattr(db_obj, field, obj_data[field])
        db.add(db_obj)
        db.commit()
        db.refresh(db_obj)
        return db_obj

    def delete(self, db: Session, *, id: int) -> T:
        """
        Delete a record by ID.

        :param db: SQLAlchemy database session.
        :param id: ID of the record to delete.
        :return: The deleted object.
        """
        obj = db.query(self.model).get(id)
        db.delete(obj)
        db.commit()
        return obj

    def read_all(self, db: Session) -> List[T]:
        """
        Get all records of the model.

        :param db: SQLAlchemy database session.
        :return: List of database record objects.
        """
        return db.query(self.model).all()


=== Content of /home/sam/github/data-fastapi/app/api/v1/dataset_routes.py ===

# app/api/v1/dataset_routes.py
from fastapi import APIRouter, Depends
from app.services.basic_crud_operations import CRUDOperations
from app.models.sql_models.docs_categ_metadata import (
    PdfDownload,
)  # Import the necessary model
from app.core.database.orm_connection import session_scope

router = APIRouter()


# Example route
@router.get("/datasets")
async def get_datasets():
    with session_scope() as session:
        crud_service = CRUDOperations(PdfDownload)
        return crud_service.read_all(session)


=== Content of /home/sam/github/data-fastapi/alembic/env.py ===

from logging.config import fileConfig
from sqlalchemy import engine_from_config, pool
from alembic import context
import os
import sys

# Important: Add the app directory to the sys.path
sys.path.append(os.getcwd())

from app.core.database.orm_connection import Base  # Import the Base from your models
from app.config.settings import settings  # Import your settings

# Alembic Config object
config = context.config

# Overwrite the sqlalchemy.url from alembic.ini with the one from settings
config.set_main_option("sqlalchemy.url", settings.sqlalchemy_database_url)

if config.config_file_name is not None:
    fileConfig(config.config_file_name)


# Set the target metadata for autogenerate
target_metadata = Base.metadata

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def run_migrations_offline():
    url = config.get_main_option("sqlalchemy.url")
    context.configure(url=url, target_metadata=target_metadata, literal_binds=True)
    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online():
    connectable = engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )
    with connectable.connect() as connection:
        context.configure(connection=connection, target_metadata=target_metadata)
        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
